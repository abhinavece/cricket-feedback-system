# =============================================================================
# AI Service Environment Variables
# =============================================================================
# Copy this file to .env in the ai-service/ directory
# This service handles payment screenshot parsing using AI vision models
# =============================================================================

# -----------------------------------------------------------------------------
# Master Kill Switch
# -----------------------------------------------------------------------------
# AI_SERVICE_ENABLED: Enable/disable the AI service (true/false)
#   Set to false to completely disable AI processing
#   Useful for maintenance or cost control
# -----------------------------------------------------------------------------
AI_SERVICE_ENABLED=true

# -----------------------------------------------------------------------------
# AI Provider Configuration
# -----------------------------------------------------------------------------
# AI_PROVIDER: Which AI provider to use
#   Options: google_ai_studio, openrouter (future)
#   Default: google_ai_studio
# -----------------------------------------------------------------------------
AI_PROVIDER=google_ai_studio

# -----------------------------------------------------------------------------
# Google AI Studio (Gemini) Configuration
# -----------------------------------------------------------------------------
# GOOGLE_AI_STUDIO_API_KEY: API key from Google AI Studio
#   Get from: https://aistudio.google.com/app/apikey
#   Required for payment screenshot parsing
# -----------------------------------------------------------------------------
GOOGLE_AI_STUDIO_API_KEY=your-google-ai-studio-api-key

# -----------------------------------------------------------------------------
# OpenRouter Configuration (Future)
# -----------------------------------------------------------------------------
# OPENROUTER_API_KEY: API key from OpenRouter (if using OpenRouter provider)
#   Get from: https://openrouter.ai/keys
# -----------------------------------------------------------------------------
# OPENROUTER_API_KEY=your-openrouter-api-key

# -----------------------------------------------------------------------------
# Cost Guardrails
# -----------------------------------------------------------------------------
# DAILY_REQUEST_LIMIT: Maximum requests per day (default: 500)
#   Prevents abuse and controls costs
#   Resets daily at midnight
#   Even free tier models have this limit
# MIN_CONFIDENCE_THRESHOLD: Minimum confidence for AI results (0.0-1.0)
#   Results below this threshold are flagged for review
#   Default: 0.7 (70% confidence)
# -----------------------------------------------------------------------------
DAILY_REQUEST_LIMIT=500
MIN_CONFIDENCE_THRESHOLD=0.7

# -----------------------------------------------------------------------------
# Service URLs
# -----------------------------------------------------------------------------
# BACKEND_CALLBACK_URL: URL of the backend service for callbacks
#   Development: http://localhost:5000
#   Kubernetes: http://backend-service:5000
#   Production: https://your-domain.com
# -----------------------------------------------------------------------------
BACKEND_CALLBACK_URL=http://localhost:5000

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
# LOG_LEVEL: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
#   Development: DEBUG or INFO
#   Production: WARNING or ERROR
# -----------------------------------------------------------------------------
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Important Notes
# -----------------------------------------------------------------------------
# 1. Only FREE tier models are allowed by default (see config.py ALLOWED_FREE_MODELS)
# 2. Paid models will be automatically blocked to prevent unexpected costs
# 3. Daily request limits apply even to free tier models
# 4. Low confidence results are flagged for manual review
# 5. All requests are logged for monitoring and debugging
